options
{
    STATIC = false;
    UNICODE_INPUT = true;
    IGNORE_CASE = true;
}

PARSER_BEGIN(MediawikiScanner)
/*******************************************************************************
 * Copyright (c) 2005,2007 Cognium Systems SA and others.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution, and is available at
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Contributors:
 *     Cognium Systems SA - initial API and implementation
 *******************************************************************************/
package org.wikimodel.wem.mediawiki.javacc;

import org.wikimodel.wem.IWikiMacroParser;
import org.wikimodel.wem.IWikiReferenceParser;
import org.wikimodel.wem.WikiMacro;
import org.wikimodel.wem.WikiParameters;
import org.wikimodel.wem.WikiReference;
import org.wikimodel.wem.impl.IWikiScannerContext;
import org.wikimodel.wem.mediawiki.MediaWikiMacroParser;
import org.wikimodel.wem.mediawiki.MediaWikiReferenceParser;

/**
 * This is the internal wiki page parser generated from the grammar file.
 *
 * @author kotelnikov
 */
public class MediawikiScanner {

    private IWikiScannerContext fContext;

    /**
     * Count number of empty lines to send when we emit the onEmptyLines event.
     * We need to count them since the number we send depend on the next block
     * element. For all block elements other than paragraph we send one more
     * empty lines since these blocks are recognized by the lexer as NewLine
     * token followed by the token for the element and thus that "eats" one
     * NewLine which is why we need to add it again.
     */
    private int emptyLinesCount = 0;

    private IWikiReferenceParser fReferenceParser = new MediaWikiReferenceParser();
    private IWikiMacroParser fMacroParser = new MediaWikiMacroParser();

    public void parse(IWikiScannerContext context) throws ParseException {
        fContext = context;
        doParse();
    }

}

PARSER_END(MediawikiScanner)

TOKEN_MGR_DECLS: {
    int tableDepth = 0;
}
<DEFAULT, INITIAL_CONTEXT> TOKEN:
{
      <#LI_SYMBOL: [ "*", "#", ":", ";" ]>
    | <#LI: (<LI_SYMBOL>)+ (<SPACE>)* >

    | <#HEADER: ("="){1, 6} >
    | <#ESCAPE: ("[[" | "~" ~[" ", "\t", "\n", "\r"]) >
    | <#BR: "<" ("br")(<SPACE>)* ("/")? ">" >
    | <#VERBATIM_BLOCK: (
          "<nowiki>" ( ~["<"] | "<" ~["/"] | "</" ~["n"] | "</n" ~["o"] | "</no" ~["w"] | "</now" ~["i"] | "</nowi" ~["k"] | "</nowik" ~["i"] | "</nowiki" ~[">"] )* "</nowiki>"
          | ("<pre>"|"<pre style=\""(<ALPHA>|<DIGIT>|<SPACE>|["#","."])+"\">") ( ~["<"] | "<" ~["/"] | "</" ~["p"] | "</p" ~["r"] | "</pr" ~["e"] | "</pre" ~[">"])*"</pre>"
        )>
    | <#VERBATIM_INLINE: (
          "<math>" ( "\\" ~[] | ~[] )* "</math>"
        ) >
    | <#REFERENCE:  ( "[[" ( "\\" ~[] | ~["[", "]"] )* "]]" | "[" ( "\\" ~[] | ~["[", "]"] )* "]" ) >
    | <#HORLINE: "---" ("-")+ >
    | <#QUOT_LINE: (" ")+ >

    | <#PARAMS: (<SPACE> | <CHAR> | <SPECIAL_SYMBOL>)* >
    | <#TABLE_BEGIN: "{|" (<PARAMS>)? >
    | <#TABLE_END: "|}" >
    | <#TABLE_CAPTION: "|+" (<PARAMS>)? >
    | <#TABLE_ROW: "|-" (<PARAMS>)?>
    | <#TABLE_CELL: ( "||" | "!!" )>
    | <#TABLE_CELL_NL: ( "|" | "!" )>

    | <#DD: (<SPACE>)* ":" (<SPACE>)* >
    | <#FORMAT_SYMBOL : (
           "'''''" | "'''" | "''"
         | "<code>" | "</code>"
         | "<sub>" | "</sub>"
         | "<sup>" | "</sup>"
         | "<tt>" | "</tt>"
         | "<ref>" | "</ref>"
         | "<ref name=\""(<ALPHA>|<DIGIT>|<SPACE>)+"\">"
         | "<del>" | "</del>"
         | "<s>" | "</s>"
         ) >

    //MediaWiki Magic Words and Extensions.
    | <#MACRO: ("{{"( "\\" ~[] | ~["{", "}"] )*"}}" | "__"(< ALPHA >)+"__" | "<references" ( <SPACE> )* "/>") >
    | <#NO_INCLUDE: ("<noinclude>"|"</noinclude>") >

// <common-tokens>
    // =========================================================================
    // New lines, spaces, special symbols and character definitions
    // =========================================================================
    | <#NEW_LINE : "\r\n" | "\r" | "\n" >
    | <#SPACE : [" ", "\t"] >
      // All special symbols from the range 0-127
    | <#SPECIAL_SYMBOL : [
        "!",     "\"",     "#",     "$",     "%",     "&",     "'",     "(",  
        ")",     "*",      "+",     ",",     "-",     ".",     "/",     ":",  
        ";",     "<",      "=",     ">",     "?",     "@",     "[",     "\\", 
        "]",     "^",      "_",     "`",     "{",     "|",     "}",     "~" 
     ] >
      // Characters are defined as all possible symbols excluding special 
      // symbols, spaces and new lines
    | <#CHAR : ~[
        "\t",    "\n",     "\r",    " ",
        "!",     "\"",     "#",     "$",     "%",     "&",     "'",     "(",  
        ")",     "*",      "+",     ",",     "-",     ".",     "/",     ":",  
        ";",     "<",      "=",     ">",     "?",     "@",     "[",     "\\", 
        "]",     "^",      "_",     "`",     "{",     "|",     "}",     "~" 
    ] >
    // =========================================================================
    // URI syntax recognition.
    // =========================================================================
    // This grammar recognize the full URI syntax with following exceptions:
    //  * It has a simplified hier-part definition: it does not contain an empty 
    //    path (so the sequences like "here: " are not recognized as URIs).
    //  * It has a simplified version of the host definition: it does not contain
    //    explicit IP definitions. 
    //  * It parses "extended" URI syntax where "opaque" URIs are treated as 
    //    having multiple schema parts
    //    Example: in an opaque URI like "download:http://www.foo.com/bar.zip"
    //    the part "download:http" is treated as a "composite" scheme part.
    //
    // See also:
    //  * http://tools.ietf.org/html/rfc3986#page-49 - the official URI grammar
    //  * http://en.wikipedia.org/wiki/Uniform_Resource_Identifier
    //  * http://en.wikipedia.org/wiki/URI_scheme#Generic_syntax
    //  * http://www.iana.org/assignments/uri-schemes.html
    // =========================================================================
    | <#URI: <URI_SCHEME_COMPOSITE> ":" <URI_HIER_PART> ("?" <URI_QUERY>)? ("#" <URI_FRAGMENT>)? >

    | <#ALPHA: ( ["A"-"Z", "a"-"z"] )>
    | <#DIGIT: ["0"-"9"]>
    | <#HEXDIG: ( <DIGIT> | ["A"-"F"] | ["a"-"f"] ) >
    | <#URI_GEN_DELIMS: [ ":", "/", "?", "#", "[", "]", "@" ]>

    // Some default can not be accepted in the text - like "," symbols 
    //<#URI_SUB_DELIMS: [ "!", "$", "&", "'", "(", ")", "*", "+", ",", ";", "=" ]>
    | <#URI_SUB_DELIMS: [ "!", "$", "&", "'", "(", ")", "*", "+", /*",",*/ ";", "=" ]>
    | <#URI_UNRESERVED: ( <ALPHA> | <DIGIT> | "-" | "." | "_" | "~" )>
    | <#URI_RESERVED: ( <URI_GEN_DELIMS> | <URI_SUB_DELIMS> ) >
    | <#URI_SCHEME: <ALPHA> ( <ALPHA> | <DIGIT> | "+" | "-" | "." )* >
    | <#URI_SCHEME_COMPOSITE: <URI_SCHEME> ( ":" <URI_SCHEME> )* >
    | <#URI_PCT_ENCODED: "%" <HEXDIG> <HEXDIG> >
    | <#URI_PCHAR_FIRST:  ( <URI_UNRESERVED> | <URI_PCT_ENCODED> | <URI_SUB_DELIMS> ) >
    | <#URI_PCHAR:  ( <URI_PCHAR_FIRST> | ":" | "@" ) >
    | <#URI_QUERY:    ( <URI_PCHAR> | "/" | "?" )* >
    | <#URI_FRAGMENT: ( <URI_PCHAR> | "/" | "?" )* >
      // A simplified hier-part definition: it does not contain an empty path.
    | <#URI_HIER_PART: ( "//" <URI_AUTHORITY> <URI_PATH_ABEMPTY> | <URI_PATH_ABSOLUTE> | <URI_PATH_ROOTLESS> )>
    | <#URI_AUTHORITY: ( <URI_USERINFO> "@" )? <URI_HOST> ( ":" <URI_PORT> )? >
    | <#URI_USERINFO: ( <URI_UNRESERVED> | <URI_PCT_ENCODED> | <URI_SUB_DELIMS> | ":" )* >
    | <#URI_PATH_ABEMPTY: ( "/" <URI_SEGMENT> )* >
    | <#URI_PATH_ABSOLUTE: "/" ( <URI_SEGMENT_NZ> ( "/" <URI_SEGMENT> )* )? >
    | <#URI_PATH_ROOTLESS: <URI_PCHAR_FIRST> <URI_SEGMENT_NZ_NC> ( "/" <URI_SEGMENT> )* >
    | <#URI_SEGMENT: (<URI_PCHAR>)* >
    | <#URI_SEGMENT_NZ: (<URI_PCHAR>)+ >
    | <#URI_SEGMENT_NZ_NC: (<URI_UNRESERVED> | <URI_PCT_ENCODED> | <URI_SUB_DELIMS> | "@")+ >
    | <#URI_PORT: (<DIGIT>)+ >
      // A simplified version of the host: it does not contain explicit IP definitions
    | <#URI_HOST: ( <URI_REG_NAME> ) >
    | <#URI_REG_NAME: ( <URI_UNRESERVED> | <URI_PCT_ENCODED> | <URI_SUB_DELIMS> )* >
    // =========================================================================
// </common-tokens>

}

<INITIAL_CONTEXT> TOKEN:
{
// <initial-context>
      <I_ESCAPE: <ESCAPE> > : DEFAULT
    | <I_TABLE_BEGIN: (<NEW_LINE>)? <TABLE_BEGIN> > : DEFAULT
    | <I_TABLE_END: (<NEW_LINE>)? <TABLE_END> > : DEFAULT
    | <I_TABLE_CAPTION: (<NEW_LINE>)? <TABLE_CAPTION>> : DEFAULT
    | <I_TABLE_ROW: (<NEW_LINE>)? <TABLE_ROW> > : DEFAULT
    | <I_TABLE_CELL: <TABLE_CELL> > : DEFAULT
    | <I_TABLE_CELL_NL: (<NEW_LINE>)? <TABLE_CELL_NL> > : DEFAULT

    | <I_LIST_ITEM: (<NEW_LINE>)? <LI> > : DEFAULT
    | <I_HEADER_BEGIN: (<NEW_LINE>)? <HEADER> (<SPACE>)* > : DEFAULT
    | <I_HORLINE: (<NEW_LINE>)? <HORLINE> > : DEFAULT

    | <I_REFERENCE : <REFERENCE> > : DEFAULT
    | <I_HEADER_END: <HEADER> > : DEFAULT
    | <I_DD: <DD> > : DEFAULT
    | <I_VERBATIM_BLOCK : <VERBATIM_BLOCK> > : DEFAULT
    | <I_VERBATIM_INLINE : <VERBATIM_INLINE> > : DEFAULT
    | <I_FORMAT_SYMBOL : <FORMAT_SYMBOL> > : DEFAULT
    | <I_BR : <BR> > : DEFAULT
    | <I_QUOT_LINE: (<NEW_LINE>)? <QUOT_LINE> > : DEFAULT
    | <I_MACRO :<MACRO> > : DEFAULT
    | <I_NO_INCLUDE :<NO_INCLUDE> > : DEFAULT

    // "Standard" tokens. They are the same for all wikis.
    | <I_URI : <URI> > : DEFAULT
    | <I_NL: (<NEW_LINE>)? > : DEFAULT
    | <I_SPACE : ( <SPACE> )+ > : DEFAULT
    | <I_WORD : ( <CHAR> )+ > : DEFAULT
    | <I_SPECIAL_SYMBOL : <SPECIAL_SYMBOL> > : DEFAULT
// </initial-context>
}

<DEFAULT> TOKEN:
{
// <default-context>
      <D_ESCAPE: <ESCAPE> > : DEFAULT
    | <D_TABLE_BEGIN: <NEW_LINE> <TABLE_BEGIN> > : DEFAULT
    | <D_TABLE_END: <NEW_LINE> <TABLE_END> > : DEFAULT
    | <D_TABLE_CAPTION: <NEW_LINE> <TABLE_CAPTION>> : DEFAULT
    | <D_TABLE_ROW: <NEW_LINE> <TABLE_ROW> > : DEFAULT
    | <D_TABLE_CELL: <TABLE_CELL> > : DEFAULT
    | <D_TABLE_CELL_NL: <NEW_LINE> <TABLE_CELL_NL> > : DEFAULT

    | <D_LIST_ITEM: <NEW_LINE> <LI> > : DEFAULT
    | <D_HEADER_BEGIN: <NEW_LINE> <HEADER> (<SPACE>)* > : DEFAULT
    | <D_HORLINE: <NEW_LINE> <HORLINE> > : DEFAULT

    | <D_REFERENCE : <REFERENCE> > : DEFAULT
    | <D_HEADER_END: <HEADER> > : DEFAULT
    | <D_DD: <DD> > : DEFAULT
    | <D_VERBATIM_BLOCK : <VERBATIM_BLOCK> > : DEFAULT
    | <D_VERBATIM_INLINE : <VERBATIM_INLINE> > : DEFAULT
    | <D_FORMAT_SYMBOL : <FORMAT_SYMBOL> > : DEFAULT
    | <D_BR : <BR> > : DEFAULT
    | <D_QUOT_LINE: <NEW_LINE> <QUOT_LINE> > : DEFAULT
    | <D_MACRO :<MACRO> > : DEFAULT
    | <D_NO_INCLUDE :<NO_INCLUDE> > : DEFAULT

    // "Standard" tokens. They are the same for all wikis.
    | <D_URI : <URI> > : DEFAULT
    | <D_NL: <NEW_LINE> > : DEFAULT
    | <D_SPACE : ( <SPACE> )+ > : DEFAULT
    | <D_WORD : ( <CHAR> )+ > : DEFAULT
    | <D_SPECIAL_SYMBOL : <SPECIAL_SYMBOL> > : DEFAULT
// </default-context>
}

// <getters>
    Token getESCAPE(): {Token t=null;} {(t=<I_ESCAPE>|t=<D_ESCAPE>){return t;}}
    Token getTABLE_BEGIN(): {Token t=null;} {(t=<I_TABLE_BEGIN>|t=<D_TABLE_BEGIN>){return t;}}
    Token getTABLE_END(): {Token t=null;} {(t=<I_TABLE_END>|t=<D_TABLE_END>){return t;}}
    Token getTABLE_CAPTION(): {Token t=null;} {(t=<I_TABLE_CAPTION>|t=<D_TABLE_CAPTION>){return t;}}
    Token getTABLE_ROW(): {Token t=null;} {(t=<I_TABLE_ROW>|t=<D_TABLE_ROW>){return t;}}
    Token getTABLE_CELL(): {Token t=null;} {(t=<I_TABLE_CELL>|t=<D_TABLE_CELL>){return t;}}
    Token getTABLE_CELL_NL(): {Token t=null;} {(t=<I_TABLE_CELL_NL>|t=<D_TABLE_CELL_NL>){return t;}}

    Token getLIST_ITEM(): {Token t=null;} {(t=<I_LIST_ITEM>|t=<D_LIST_ITEM>){return t;}}
    Token getHEADER_BEGIN(): {Token t=null;} {(t=<I_HEADER_BEGIN>|t=<D_HEADER_BEGIN>){return t;}}
    Token getHORLINE(): {Token t=null;} {(t=<I_HORLINE>|t=<D_HORLINE>){return t;}}

    Token getREFERENCE(): {Token t=null;} {(t=<I_REFERENCE>|t=<D_REFERENCE>){return t;}}
    Token getHEADER_END(): {Token t=null;} {(t=<I_HEADER_END>|t=<D_HEADER_END>){return t;}}
    Token getDD(): {Token t=null;} {(t=<I_DD>|t=<D_DD>){return t;}}
    Token getVERBATIM_BLOCK(): {Token t=null;} {(t=<I_VERBATIM_BLOCK>|t=<D_VERBATIM_BLOCK>){return t;}}
    Token getVERBATIM_INLINE(): {Token t=null;} {(t=<I_VERBATIM_INLINE>|t=<D_VERBATIM_INLINE>){return t;}}
    Token getFORMAT_SYMBOL(): {Token t=null;} {(t=<I_FORMAT_SYMBOL>|t=<D_FORMAT_SYMBOL>){return t;}}
    Token getBR(): {Token t=null;} {(t=<I_BR>|t=<D_BR>){return t;}}
    Token getQUOT_LINE(): {Token t=null;} {(t=<I_QUOT_LINE>|t=<D_QUOT_LINE>){return t;}}
    Token getMACRO(): {Token t=null;} {(t=<I_MACRO>|t=<D_MACRO>){return t;}}
    Token getNO_INCLUDE(): {Token t=null;} {(t=<I_NO_INCLUDE>|t=<D_NO_INCLUDE>){return t;}}

    // "Standard" tokens. They are the same for all wikis.
    Token getURI(): {Token t=null;} {(t=<I_URI>|t=<D_URI>){return t;}}
    Token getNL(): {Token t=null;} {(t=<I_NL>|t=<D_NL>){return t;}}
    Token getSPACE(): {Token t=null;} {(t=<I_SPACE>|t=<D_SPACE>){return t;}}
    Token getWORD(): {Token t=null;} {(t=<I_WORD>|t=<D_WORD>){return t;}}
    Token getSPECIAL_SYMBOL(): {Token t=null;} {(t=<I_SPECIAL_SYMBOL>|t=<D_SPECIAL_SYMBOL>){return t;}}
// </getters>

void doParse():
{
    token_source.SwitchTo(token_source.INITIAL_CONTEXT);
}
{
    {
        fContext.beginDocument();
    }
    ( docElements() )*
    <EOF>
    {
        sendOnEmptyLinesEvent(true);
        fContext.endDocument();
    }
}

void docElements():
{
}
{
    LOOKAHEAD(2) macro()
    |
    noInclude()
    |
    LOOKAHEAD(2) table()
    |
    header()
    |
    list()
    |
    verbatimBlock()
    |
    horline()
    |
    (
    LOOKAHEAD(2)
        quot()
        |
        paragraph()
    )
    |
    emptyParagraph()
}

void macro():
{
   Token t = null;
}
{
    t = getMACRO()
    {
        sendOnEmptyLinesEvent(false);
        String str=t.image.trim();
        WikiMacro macro = fMacroParser.parse(str);
        fContext.onMacro(macro.getName(), macro.getWikiParameters(), macro.getContent(), false);
    }
}

void noInclude():
{
   Token t = null;
}
{
    t = getNO_INCLUDE()
    {
        sendOnEmptyLinesEvent(true);
    }
}

void header():
{
   Token t = null;
}
{
    t = getHEADER_BEGIN()
    {
        sendOnEmptyLinesEvent(true);
        int level = t.image.trim().length();
        fContext.beginHeader(level);
    }
    (LOOKAHEAD(2) line())?
    {
        fContext.endHeader();
    }
}

void table():
{
    Token t = null;
    String str = "";
    WikiParameters params = null;
}
{

    t = getTABLE_BEGIN()
    {
        sendOnEmptyLinesEvent(true);
        str=t.image.trim();
        str=str.substring("{|".length()).trim();
        params = new WikiParameters(str);
        fContext.beginTable(params);
    }
    |
    t = getTABLE_END()
    {
      fContext.endTable();
    }
    |
    t = getTABLE_CAPTION()
    {
        if  (fContext.isInTable())  {
            str = t.image.trim();
            str = str.substring("|+".length()).trim();
            fContext.onTableCaption(str);
        }
    }
    |
    t = getTABLE_ROW()
    {
        if  (fContext.isInTable())  {
            str = t.image.trim();
            str = str.substring("|-".length()).trim();
            params = new WikiParameters(str);
            fContext.onTableRow(params);
        }
    }
    |
    {
      // no need to call beginTable() event here because it's called automatically
    }
    ( LOOKAHEAD(2) tableRow() )+
    {
       // no need to call endTable() event here because it's called automatically
    }
}

void tableRow():
{
    Token t = null;
}
{
    ( t = getTABLE_CELL_NL() )
    {
        sendOnEmptyLinesEvent(true);
        String str = t.image.trim();
        boolean head  = str.startsWith("!");
        fContext.beginTableCell(head);
    }
    ( LOOKAHEAD(2) block() )*
    {
    }
}

void list():
{
}
{
    {
        sendOnEmptyLinesEvent(true);
        fContext.beginList();
    }
    ( LOOKAHEAD(2) listItem() )+
    {
        fContext.endList();
    }
}

void listItem():
{
    Token t = null;
}
{
    t = getLIST_ITEM()
    {
        sendOnEmptyLinesEvent(true);
        fContext.beginListItem(t.image);
    }
    ( LOOKAHEAD(2) block() )*
    {
        fContext.endListItem();
    }
}

void block():
{
}
{
    ( lines() | verbatimBlock() )
}

void verbatimBlock():
{
    Token t = null;
}
{
    t = getVERBATIM_BLOCK()
    {
        sendOnEmptyLinesEvent(true);
        String str = t.image.trim();
        String tag=str.substring(1,str.indexOf('>'));
        int len = 0;
        int end = 0;
        WikiParameters params = null;
        if ("nowiki".equalsIgnoreCase(tag)|| "pre".equalsIgnoreCase(tag)) {
            len = tag.length()+2;
            end = len;
            str = str.substring(len, str.length() - end - 1);
            fContext.onVerbatim(str, false);
        } else if (str.startsWith("<pre")) {
            len = str.indexOf('>')+1;
            end = "<pre>".length();
            params=new WikiParameters(str.substring("<pre".length(),len-1));
            str = str.substring(len, str.length() - end - 1);
            fContext.onVerbatim(str, false,params);
        }
    }
}

void horline():
{
    Token t = null;
}
{
    t = getHORLINE()
    {
        fContext.onHorizontalLine();
    }
}

void paragraph():
{
    Token t = null;
    String str = "";
}
{
    {
        sendOnEmptyLinesEvent(true);
        fContext.beginParagraph();
    }
    lines()
    {
        fContext.endParagraph();
    }
}

void quot():
{
    Token t = null;
    int depthCounter = 0;
}
{
    {
        fContext.beginQuot();
    }
    quotLine()
    ( LOOKAHEAD(2)
        getNL()
        quotLine()
    )*
    {
        fContext.endQuot();
    }
}

void quotLine():
{
    Token t = null;
    String str = "";
}
{
    t = getQUOT_LINE()
    {
        str = t.image.trim();
        int depth = str.length();
        fContext.beginQuotLine(depth);
    }
    (LOOKAHEAD(2) line() )?
    {
        fContext.endQuotLine();
    }
}

void emptyParagraph():
{
}
{
    getNL() (LOOKAHEAD(2) getNL() { emptyLinesCount++; })*
}


void lines():
{
}
{
    line()
    ( LOOKAHEAD(2)
        newLine()
        line()
    )*
}

void newLine():
{
}
{
    getNL()
    {
        sendOnEmptyLinesEvent(true);
        fContext.onNewLine();
    }
}

void line():
{
    Token t = null;
    String str = null;
    boolean explicitLink = false;
}
{
    ( LOOKAHEAD(2)
        (
            t = getESCAPE()
            {
                sendOnEmptyLinesEvent(true);
                fContext.onEscape("" + t.image.charAt(1));
            }
            |
            t = getWORD()
            {
                sendOnEmptyLinesEvent(true);
                fContext.onWord(t.image);
            }
            |
            t = getSPACE()
            {
                sendOnEmptyLinesEvent(true);
                fContext.onSpace(t.image);
            }
            |
            t = getSPECIAL_SYMBOL()
            {
                sendOnEmptyLinesEvent(true);
                fContext.onSpecialSymbol(t.image);
            }
            |
            t = getFORMAT_SYMBOL()
            {
                sendOnEmptyLinesEvent(true);
                str = t.image.trim();
                if (str.startsWith("<")) {
                    str = str.substring(1, str.length() - 1);
                    boolean close = str.startsWith("/");
                    if (close)
                        str = str.substring(1);
                    if ("sub".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.SUB, close);
                    } else if ("sup".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.SUP, close);
                    } else if ("code".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.CODE, close);
                    } else if ("tt".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.TT, close);
                    } else if ("ref".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.REF, close);
                    } else if ("del".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.DEL, close);
                    } else if ("s".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.STRIKE, close);
                    } else if(str.startsWith("ref")) {
                        WikiParameters params=new WikiParameters(str.substring("ref".length()+1).trim());
                        fContext.onFormat(IWikiScannerContext.REF, close);                    }
                } else {
                    if ("'''''".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.STRONG);
                        fContext.onFormat(IWikiScannerContext.EM);
                    } else if ("'''".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.STRONG);
                    } else if ("''".equals(str)) {
                        fContext.onFormat(IWikiScannerContext.EM);
                    }
                }
            }
            |
            t = getVERBATIM_INLINE()
            {
                sendOnEmptyLinesEvent(true);
                str = t.image.trim();
                int len = "<math>".length();
                str = str.substring(len, str.length() - len - 1);
                fContext.onVerbatim(str, true);
            }
            |
            t = getHEADER_END()
            {
                sendOnEmptyLinesEvent(true);
                if (!fContext.isInHeader()) {
                    fContext.onSpecialSymbol(t.image);
                }
            }
            |
            t = getBR()
            {
                sendOnEmptyLinesEvent(true);
                fContext.onLineBreak();
            }
            |
            t = getURI()
            {
                sendOnEmptyLinesEvent(true);
                fContext.onReference(t.image.trim());
            }
            |
            t = getREFERENCE()
            {
                sendOnEmptyLinesEvent(true);
                str = t.image.trim();
                if (str.startsWith("[[") && str.endsWith("]]")) {
                    str = str.substring(2, str.length() - 2);
                } else  if (str.startsWith("[")) {
                    str = str.substring(1, str.length() - 1);
                }
                str = str.trim();
                WikiReference ref = fReferenceParser.parse(str);
                int pipeCount = str.replaceAll("[^|]", "").length();
                if(str.toLowerCase().startsWith("image:")|| (str.toLowerCase().startsWith("file:") && pipeCount >1)) {
                    fContext.onImage(ref);                } else {                    fContext.onReference(ref);
                }
            }
            |
            t = getTABLE_CELL_NL()
            {
              sendOnEmptyLinesEvent(true);
                if (fContext.isInTable()) {
                    str = t.image.trim();
                    boolean headnl  = str.startsWith("!");
                    fContext.onTableCell(headnl);
                }else {
                    fContext.onSpecialSymbol(t.image);                }
            }
            |
            t = getTABLE_CELL()
            {
                sendOnEmptyLinesEvent(true);
                if (fContext.isInTable()) {
                    str = t.image.trim();
                    boolean head  = str.startsWith("!");
                    fContext.onTableCell(head);
                } else {
                    fContext.onSpecialSymbol(t.image);
                }
            }
            |
            t = getDD()
            {
                sendOnEmptyLinesEvent(true);
                if (fContext.canApplyDefintionSplitter()) {
                    fContext.onDefinitionListItemSplit();
                } else {
                    fContext.onSpecialSymbol(t.image);
                }
            }
            |
            t = getMACRO()
            {                // this is an inline macro
                sendOnEmptyLinesEvent(false);
                str = t.image.trim();
                WikiMacro macro = fMacroParser.parse(str);
                fContext.onMacro(macro.getName(), macro.getWikiParameters(), macro.getContent(), true);
            }
        )
    )+
}

/**
 * If shouldIncrement is true send one more empty lines. All block
 * elements other than paragraph should call shouldIncremet with
 * true since we need to emit one more new line for them (since the
 * lexer "eats" a NewLine token to recognize these block elements.
 */
void sendOnEmptyLinesEvent(boolean shouldIncrement):
{
}
{
    {
        if (emptyLinesCount > 1) {
            fContext.onEmptyLines(shouldIncrement ? emptyLinesCount : emptyLinesCount - 1);
        }
        emptyLinesCount = 0;
    }
}